{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZkclPOMOs6eo"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random\n",
        "import shutil\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from shutil import copyfile\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Download the dataset from gDrive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "id": "IuZ2DkKmPrwR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c25728d-fae6-4490-dd49-a3cf4d4a8165"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "zip_file = '/content/drive/Shareddrives/Capstone Project/ML/Data/dataset1.zip'\n",
        "zip_ref   = zipfile.ZipFile(zip_file, 'r')\n",
        "zip_ref.extractall('/content/drive/Shareddrives/Capstone Project/ML/Data/')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "ZkPy6DG0t1yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source = '/content/drive/Shareddrives/Capstone Project/ML/Data/dataset1/'\n",
        "sourceAcnes = os.path.join(source, 'acnes')\n",
        "sourceBlackheads = os.path.join(source, 'blackheads')\n",
        "sourceDarkSpots = os.path.join(source, 'darkspots')\n",
        "sourceWrinkles = os.path.join(source, 'wrinkles')\n",
        "\n",
        "print(f\"There are {len(os.listdir(sourceAcnes))} images of acnes.\")\n",
        "print(f\"There are {len(os.listdir(sourceBlackheads))} images of blackheads.\")\n",
        "print(f\"There are {len(os.listdir(sourceDarkSpots))} images of darkspots.\")\n",
        "print(f\"There are {len(os.listdir(sourceWrinkles))} images of wrinkles.\")"
      ],
      "metadata": {
        "id": "vnhPRagXk21K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "70a87e1a-e6c4-4738-e906-4f4580a3b3a2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 999 images of acnes.\n",
            "There are 150 images of blackheads.\n",
            "There are 303 images of darkspots.\n",
            "There are 300 images of wrinkles.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Define root directory\n",
        "root_dir = '/content/drive/Shareddrives/Capstone Project/skin-case/'\n",
        "\n",
        "# Empty directory to prevent FileExistsError if the function is run several times\n",
        "if os.path.exists(root_dir):\n",
        "    shutil.rmtree(root_dir)\n",
        "\n",
        "# Create train and validation directories\n",
        "def create_train_val_dirs(root_path):\n",
        "    # train and validation directories for skin-case\n",
        "    train_dir = os.path.join(root_dir, 'training')\n",
        "    os.makedirs(train_dir, exist_ok=True)\n",
        "    val_dir = os.path.join(root_dir, 'validation')\n",
        "    os.makedirs(val_dir, exist_ok=True)\n",
        "    \n",
        "    # train directories for acnes\n",
        "    train_acnes_dir = os.path.join(train_dir, 'acnes')\n",
        "    os.makedirs(train_acnes_dir, exist_ok=True)\n",
        "    # train directories for blackheads\n",
        "    train_blackheads_dir = os.path.join(train_dir, 'blackheads')\n",
        "    os.makedirs(train_blackheads_dir, exist_ok=True)\n",
        "    # train directories for darkspots\n",
        "    train_darkspots_dir = os.path.join(train_dir, 'darkspots')\n",
        "    os.makedirs(train_darkspots_dir, exist_ok=True)\n",
        "    # train directories for wrinkles\n",
        "    train_wrinkles_dir = os.path.join(train_dir, 'wrinkles')\n",
        "    os.makedirs(train_wrinkles_dir, exist_ok=True)\n",
        "\n",
        "    # validation directories for acnes\n",
        "    val_acnes_dir = os.path.join(val_dir, 'acnes')\n",
        "    os.makedirs(val_acnes_dir, exist_ok=True)\n",
        "    # validation directories for blackheads\n",
        "    val_blackheads_dir = os.path.join(val_dir, 'blackheads')\n",
        "    os.makedirs(val_blackheads_dir, exist_ok=True)\n",
        "    # validation directories for darkspots\n",
        "    val_darkspots_dir = os.path.join(val_dir, 'darkspots')\n",
        "    os.makedirs(val_darkspots_dir, exist_ok=True)\n",
        "    # validation directories for wrinkles\n",
        "    val_wrinkles_dir = os.path.join(val_dir, 'wrinkles')\n",
        "    os.makedirs(val_wrinkles_dir, exist_ok=True)\n",
        "\n",
        "try:\n",
        "    create_train_val_dirs(root_path=root_dir)\n",
        "except FileExistsError:\n",
        "    print(\"You should not be seeing this since the upper directory is removed beforehand\")\n",
        "\n",
        "# Print all directories\n",
        "#for rootdir, dirs, files in os.walk(root_dir):\n",
        "#    for subdir in dirs:\n",
        "#        print(os.path.join(rootdir, subdir))"
      ],
      "metadata": {
        "id": "l9uwc9URBIR9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def split_data(SOURCE_DIR, TRAINING_DIR, VALIDATION_DIR, SPLIT_SIZE):\n",
        "  files = []\n",
        "  for filename in os.listdir(SOURCE_DIR):\n",
        "    file = SOURCE_DIR + filename\n",
        "    if os.path.getsize(file) > 0:\n",
        "      files.append(filename)\n",
        "    else:\n",
        "      print(filename + ' is zero length, so ignoring.') \n",
        "    \n",
        "    all_files = len(files)\n",
        "    train_length = int(all_files * SPLIT_SIZE)\n",
        "    test_length = int(all_files - train_length)\n",
        "    shuffled = random.sample(files, all_files)\n",
        "    train_set = shuffled[0:train_length]\n",
        "    test_set = shuffled[train_length:]\n",
        "\n",
        "  for filename in train_set:\n",
        "    src_file = SOURCE_DIR + filename\n",
        "    dest_file = TRAINING_DIR + filename\n",
        "    copyfile(src_file, dest_file)\n",
        "\n",
        "  for filename in test_set:\n",
        "    src_file = SOURCE_DIR + filename\n",
        "    dest_file = VALIDATION_DIR + filename\n",
        "    copyfile(src_file, dest_file)\n",
        "\n",
        "  pass"
      ],
      "metadata": {
        "id": "azYuowBqdF5m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your split_data function\n",
        "\n",
        "# Define paths\n",
        "ACNES_SOURCE_DIR = \"/content/drive/Shareddrives/Capstone Project/ML/Data/dataset1/acnes/\"\n",
        "BLACKHEADS_SOURCE_DIR = \"/content/drive/Shareddrives/Capstone Project/ML/Data/dataset1/blackheads/\"\n",
        "DARKSPOTS_SOURCE_DIR = \"/content/drive/Shareddrives/Capstone Project/ML/Data/dataset1/darkspots/\"\n",
        "WRINKLES_SOURCE_DIR = \"/content/drive/Shareddrives/Capstone Project/ML/Data/dataset1/wrinkles/\"\n",
        "\n",
        "TRAINING_DIR = \"/content/drive/Shareddrives/Capstone Project/skin-case/training\"\n",
        "VALIDATION_DIR = \"/content/drive/Shareddrives/Capstone Project/skin-case/validation\"\n",
        "\n",
        "TRAINING_ACNES_DIR = os.path.join(TRAINING_DIR, \"acnes/\")\n",
        "VALIDATION_ACNES_DIR = os.path.join(VALIDATION_DIR, \"acnes/\")\n",
        "\n",
        "TRAINING_BLACKHEADS_DIR = os.path.join(TRAINING_DIR, \"blackheads/\")\n",
        "VALIDATION_BLACKHEADS_DIR = os.path.join(VALIDATION_DIR, \"blackheads/\")\n",
        "\n",
        "TRAINING_DARKSPOTS_DIR = os.path.join(TRAINING_DIR, \"darkspots/\")\n",
        "VALIDATION_DARKSPOTS_DIR = os.path.join(VALIDATION_DIR, \"darkspots/\")\n",
        "\n",
        "TRAINING_WRINKLES_DIR = os.path.join(TRAINING_DIR, \"wrinkles/\")\n",
        "VALIDATION_WRINKLES_DIR = os.path.join(VALIDATION_DIR, \"wrinkles/\")\n",
        "\n",
        "# Empty directories in case you run this cell multiple times\n",
        "if len(os.listdir(TRAINING_WRINKLES_DIR)) > 0:\n",
        "  for file in os.scandir(TRAINING_WRINKLES_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "if len(os.listdir(VALIDATION_WRINKLES_DIR)) > 0:\n",
        "  for file in os.scandir(VALIDATION_WRINKLES_DIR):\n",
        "    os.remove(file.path)\n",
        "\n",
        "# Define proportion of images used for training\n",
        "split_size = .8\n"
      ],
      "metadata": {
        "id": "BZxvS6uucZE6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the function\n",
        "# NOTE: Messages about zero length images should be printed out\n",
        "split_data(ACNES_SOURCE_DIR, TRAINING_ACNES_DIR, VALIDATION_ACNES_DIR, split_size)\n",
        "split_data(BLACKHEADS_SOURCE_DIR, TRAINING_BLACKHEADS_DIR, VALIDATION_BLACKHEADS_DIR, split_size)\n",
        "split_data(DARKSPOTS_SOURCE_DIR, TRAINING_DARKSPOTS_DIR, VALIDATION_DARKSPOTS_DIR, split_size)\n",
        "split_data(WRINKLES_SOURCE_DIR, TRAINING_WRINKLES_DIR, VALIDATION_WRINKLES_DIR, split_size)\n",
        "\n",
        "# Your function should perform copies rather than moving images so original directories should contain unchanged images\n",
        "print(f\"\\n\\nOriginal acne's directory has {len(os.listdir(ACNES_SOURCE_DIR))} images\")\n",
        "\n",
        "# Training and validation splits. Check that the number of images matches the expected output.\n",
        "print(f\"There are {len(os.listdir(TRAINING_WRINKLES_DIR))} images of acnes for training\")\n",
        "print(f\"There are {len(os.listdir(VALIDATION_WRINKLES_DIR))} images of acnes for validation\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CrsEhiQ2REI",
        "outputId": "a3f7ea84-8041-4077-ae22-f6b21531b32a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Original acne's directory has 999 images\n",
            "There are 240 images of acnes for training\n",
            "There are 60 images of acnes for validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_generators(TRAINING_DIR, VALIDATION_DIR):\n",
        "  \"\"\"\n",
        "  Creates the training and validation data generators\n",
        "  \n",
        "  Args:\n",
        "    TRAINING_DIR (string): directory path containing the training images\n",
        "    VALIDATION_DIR (string): directory path containing the testing/validation images\n",
        "    \n",
        "  Returns:\n",
        "    train_generator, validation_generator - tuple containing the generators\n",
        "  \"\"\"\n",
        "  ### START CODE HERE\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the arguments to augment the images)\n",
        "  train_datagen = ImageDataGenerator(rescale=1./255.,\n",
        "                                     rotation_range=40,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     shear_range=0.2,\n",
        "                                     zoom_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     fill_mode='nearest')\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR,\n",
        "                                                      batch_size=57,\n",
        "                                                      class_mode='categorical',\n",
        "                                                      target_size=(150, 150))\n",
        "\n",
        "  # Instantiate the ImageDataGenerator class (don't forget to set the rescale argument)\n",
        "  validation_datagen = ImageDataGenerator(rescale=1./255.)\n",
        "\n",
        "  # Pass in the appropriate arguments to the flow_from_directory method\n",
        "  validation_generator = validation_datagen.flow_from_directory(directory=VALIDATION_DIR,\n",
        "                                                                batch_size=20,\n",
        "                                                                class_mode='categorical',\n",
        "                                                                target_size=(150, 150))\n",
        "  ### END CODE HERE\n",
        "  return train_generator, validation_generator"
      ],
      "metadata": {
        "id": "cu0Cq9Wi_wrn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test your generators\n",
        "train_generator, validation_generator = train_val_generators(TRAINING_DIR, VALIDATION_DIR)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZHelvmASFctG",
        "outputId": "ed630664-dd7d-405b-b28e-e6c7d4050e09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1401 images belonging to 4 classes.\n",
            "Found 351 images belonging to 4 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a Callback class that stops training once accuracy reaches 99.9%\n",
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs={}):\n",
        "    if(logs.get('val_acc')>0.87):\n",
        "      print(\"\\nReached 99.9% accuracy so cancelling training!\")\n",
        "      self.model.stop_training = True"
      ],
      "metadata": {
        "id": "Toz7o1iwCcdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# GRADED FUNCTION: create_model\n",
        "def create_model():\n",
        "  # DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n",
        "  # USE AT LEAST 3 CONVOLUTION LAYERS\n",
        "\n",
        "  ### START CODE HERE\n",
        "\n",
        "  model = tf.keras.models.Sequential([ \n",
        "      # Conv2D and MaxPooling2D layers\n",
        "      tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(150,150,3)),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      #tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "      #tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      # Dense layers\n",
        "      # tf.keras.layers.Flatten(),\n",
        "      #tf.keras.layers.Dropout(0.2),\n",
        "      #tf.keras.layers.Dense(units=64, activation='relu', input_shape=(150,150,3)),\n",
        "      #tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(150,150,3)),\n",
        "      tf.keras.layers.MaxPooling2D(2,2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      #tf.keras.layers.Dense(512, activation='relu'),\n",
        "      tf.keras.layers.Dense(256, activation='relu'),\n",
        "      tf.keras.layers.Dense(4, activation='softmax')\n",
        "  ])\n",
        "  \n",
        "  model.compile(optimizer='Adam',\n",
        "                loss='categorical_crossentropy',\n",
        "                metrics=['acc']) \n",
        "  \n",
        "  return model"
      ],
      "metadata": {
        "id": "qN95KqkcB7Oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the untrained model\n",
        "model = create_model()\n",
        "\n",
        "# Train the model\n",
        "# Note that this may take some time.\n",
        "callbacks = myCallback()\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=50,\n",
        "                    verbose=2,\n",
        "                    validation_data=validation_generator,\n",
        "                    callbacks=callbacks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WmtOu9kyFMV4",
        "outputId": "0c602773-8457-4a01-ffd6-0c2b2c662ce8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "25/25 - 103s - loss: 0.7514 - acc: 0.6888 - val_loss: 0.4671 - val_acc: 0.7350 - 103s/epoch - 4s/step\n",
            "Epoch 2/50\n",
            "25/25 - 96s - loss: 0.4952 - acc: 0.7459 - val_loss: 0.4545 - val_acc: 0.8177 - 96s/epoch - 4s/step\n",
            "Epoch 3/50\n",
            "25/25 - 96s - loss: 0.4656 - acc: 0.7773 - val_loss: 0.4018 - val_acc: 0.8462 - 96s/epoch - 4s/step\n",
            "Epoch 4/50\n",
            "25/25 - 99s - loss: 0.4542 - acc: 0.7994 - val_loss: 0.3946 - val_acc: 0.8632 - 99s/epoch - 4s/step\n",
            "Epoch 5/50\n",
            "25/25 - 105s - loss: 0.4264 - acc: 0.8137 - val_loss: 0.3584 - val_acc: 0.8575 - 105s/epoch - 4s/step\n",
            "Epoch 6/50\n",
            "25/25 - 100s - loss: 0.4280 - acc: 0.8187 - val_loss: 0.3864 - val_acc: 0.8490 - 100s/epoch - 4s/step\n",
            "Epoch 7/50\n",
            "25/25 - 96s - loss: 0.4272 - acc: 0.8059 - val_loss: 0.3826 - val_acc: 0.8547 - 96s/epoch - 4s/step\n",
            "Epoch 8/50\n",
            "25/25 - 96s - loss: 0.4426 - acc: 0.7980 - val_loss: 0.3724 - val_acc: 0.8632 - 96s/epoch - 4s/step\n",
            "Epoch 9/50\n",
            "25/25 - 99s - loss: 0.4085 - acc: 0.8237 - val_loss: 0.3509 - val_acc: 0.8547 - 99s/epoch - 4s/step\n",
            "Epoch 10/50\n",
            "25/25 - 106s - loss: 0.4147 - acc: 0.8266 - val_loss: 0.3599 - val_acc: 0.8689 - 106s/epoch - 4s/step\n",
            "Epoch 11/50\n",
            "25/25 - 100s - loss: 0.3964 - acc: 0.8330 - val_loss: 0.3474 - val_acc: 0.8462 - 100s/epoch - 4s/step\n",
            "Epoch 12/50\n",
            "\n",
            "Reached 99.9% accuracy so cancelling training!\n",
            "25/25 - 96s - loss: 0.3823 - acc: 0.8494 - val_loss: 0.3278 - val_acc: 0.8718 - 96s/epoch - 4s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "dGA3Pib7x0Uj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a88fd3-f73c-4b67-c52f-4d1ab38e29a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 148, 148, 32)      896       \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 74, 74, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 72, 72, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 36, 36, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 34, 34, 128)       73856     \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 17, 17, 128)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 8, 8, 128)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 256)               2097408   \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 1028      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,191,684\n",
            "Trainable params: 2,191,684\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## NOTE: If you are using Safari and this cell throws an error,\n",
        "## please skip this block and run the next one instead.\n",
        "\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from tensorflow.keras.utils import load_img, img_to_array\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = load_img(path, target_size=(150, 150))\n",
        "  x = img_to_array(img)\n",
        "  x /= 255\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "iI2n6JtbRSru",
        "outputId": "e7ac2289-7738-4e3a-f216-17b3a0cf51eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-c4d21763-4eb8-4d01-b2d6-53e8c12020e6\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-c4d21763-4eb8-4d01-b2d6-53e8c12020e6\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving WIN_20230528_21_14_27_Pro.jpg to WIN_20230528_21_14_27_Pro.jpg\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "[4.4545406e-05 3.7424285e-02 4.4873339e-01 5.1379776e-01]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # RESIZE USING Python Imaging Library (PIL)\n",
        "# # GAUSA DI RUN, DI ATAS UDH RESIZE PAKE GENERATOR\n",
        "# from PIL import Image\n",
        "# import os\n",
        "\n",
        "# SOURCE_DIR = '/content/drive/Shareddrives/Capstone Project/ML/Data/dataset1/wrinkles/'\n",
        "# DEST_DIR = '/content/drive/Shareddrives/Capstone Project/ML/Data/dataset1/wrinkles_resized/'\n",
        "\n",
        "# # Create the destination directory if it doesn't exist\n",
        "# if not os.path.exists(DEST_DIR):\n",
        "#     os.makedirs(DEST_DIR)\n",
        "\n",
        "# # Set the desired size for the resized images\n",
        "# new_size = (224, 224)\n",
        "\n",
        "# # Iterate over each file in the source directory\n",
        "# for filename in os.listdir(SOURCE_DIR):\n",
        "#     file_path = os.path.join(SOURCE_DIR, filename)\n",
        "#     dest_file_path = os.path.join(DEST_DIR, filename)\n",
        "\n",
        "#     # Open the image\n",
        "#     image = Image.open(file_path)\n",
        "\n",
        "#     # Resize the image\n",
        "#     resized_image = image.resize(new_size)\n",
        "\n",
        "#     # Save the resized image to the destination directory\n",
        "#     resized_image.save(dest_file_path)\n",
        "\n",
        "#     print(f\"Resized image saved: {dest_file_path}\")\n"
      ],
      "metadata": {
        "id": "gzB-Z_sX2dPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# # for deleting folder\n",
        "# import shutil\n",
        "# import os\n",
        "\n",
        "# folder_path = '/content/drive/Shareddrives/Capstone Project/ML/Data/dataset1/blackhead/resized'\n",
        "\n",
        "# # Remove the folder\n",
        "# shutil.rmtree(folder_path)\n",
        "\n",
        "# # Verify if the folder is removed\n",
        "# if not os.path.exists(folder_path):\n",
        "#     print(f\"Folder {folder_path} successfully removed.\")\n",
        "# else:\n",
        "#     print(f\"Failed to remove the folder {folder_path}.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvI0qx9VBVFR",
        "outputId": "25b0796f-a888-496f-c0e4-430822f4ec8d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder /content/drive/Shareddrives/Capstone Project/ML/Data/dataset1/blackhead/resized successfully removed.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oT8FrCOrCJYK"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}